---
description: Simple post-processing in three.js using a triangle that fills the screen.
order: 3
title: Post-Processing
---

:::caution
this article is a work in progress
:::

Post-processing refers to effects that are applied to an image after rendering. Examples include tone-mapping, blurring, antialiasing, bloom effects, glitch effects, and many more. It typically involves rendering the scene to a [render target](/miscellaneous/render-targets) and then using the target's texture as input to a separate fragment shader.

import App from "@components/examples/techniques/post-processing/simple/app.svelte";
import fragmentCodeSimple from "@components/examples/techniques/post-processing/simple/fragments/simple.glsl?raw";
import vertexCode from "@components/examples/techniques/post-processing/simple/vertex.glsl?raw";

import { Code } from "@astrojs/starlight/components";

<App client:only />

Three.js provides many of these effects through its post-processing addon, however for simple effects that don't require multiple passes, using the addon might be excessive. This article will explain how to create a very simple post-processing flow tath utilizes a specific triangle that covers the entire canvas.

## Screen-Filling Triangle

The main idea is to create a geometry that will cover the entire canvas. This could easily be achieved with two triangles but there's a clever trick that uses only single triangle to achieve the same result.

:::tip[todo]
put a hand-drawn image of the triangle and the screen here
:::

Notice how the triangle's hypotenuse only touches the screen at the top left corner. Every fragment that is outside of the screen won't be visible. Taking into consideration gl's clip space which ranges from -1 to 1 in all axes, one such triangle that covers the screen has vertices **-1,-1**, **3,-1**, and **3,-1**.

We can create buffer attribute for such a triangle like so

```ts
const vertices = new Float32Array([-1, -1, 0, 3, -1, 0, -1, 3, 0]);
const geometry = new BufferGeometry().setAttribute(
	"position",
	new BufferAttribute(vertices, 3),
);
```

Notice that even though the triangle is a 2D object, we specify the vertices in 3D. This is because, three.js expects position attributes to be in sets of 3 and when it goes to compute the bounding sphere of the geometry, if the position attribute is not a multiple of 3, an error will be thrown.

:::note
The bounding sphere of a geometry is used for raycasting, frustrum culling, etc.
:::

Another way around this problem is to use a 2D set of vertices _and_ compute the bounding sphere ourselves. Doing it this way would skip over all the bounding sphere calculations.

```ts
const vertices = new Float32Array([-1, -1, 3, -1, -1, 3]);
const geometry = new BufferGeometry().setAttribute(
	"position",
	new BufferAttribute(vertices, 2),
);

const center = new Vector3();
geometry.boundingSphere = new Sphere().set(center, Infinity);
```

The 2D solution is probably preferred since the triangle mesh will always be visible and any ray that is cast into the scene will always hit it since it covers the entire canvas but I think there's also argument to be made that if three.js expects geometries a certain way, it's probably best to conform - that way there's no unintended side effects or errors further down the line.

:::caution
Whether you use the 2D or 3D version, make sure your shader attributes match, namely the **position** attribute.

```glsl title="2D" mark="vec2"
attribute vec2 position;
```

```glsl title="3D" mark="vec3"
attribute vec3 position;
```

:::

## Shaders

The scene is rendered into a render target whose texture is then sent into a custom fragment shader. The uv coordinates of the geometry are calculated in the vertex shader and sent over to the fragment shader to use as an index into the texture.

The uvs needs to range from -1 to 1. Mapping the position attribute to this range is a fairly simple conversion.

<Code
	title="vertex.glsl"
	lang="glsl"
	code={vertexCode}
/>

In the fragment shader the uvs are used to index into the texture. Remember, the texture is a rendering of the scene.

<Code
	title="fragment.glsl"
	lang="glsl"
	code={fragmentCodeSimple}
/>

## Putting it All Together

Over on the javascript/typescript side, all of these pieces come together like so:

```ts
const geometry = createScreenTriangleGeometry();

const material = new RawShaderMaterial({
	fragmentShader,
	uniforms,
	vertexShader,
});

const mesh = new Mesh(geometry, material);

mesh.frustrumCulled = false;
```

The mesh doesn't need to be frustrum culled because it is always visible.

## Rendering

:::tip[todo]
add content about rendering to the target then rendering the scene to the canvas

```ts
const ppScene = new Scene().add(mesh);
const ppCamera = new OrthographicCamera();

const render = () => {
	const last = renderer.getRenderTarget();
	renderer.setRenderTarget(renderTarget);
	renderer.render(scene, camera);
	renderer.setRenderTarget(last);
	renderer.render(ppScene, ppCamera);
};
```

:::
